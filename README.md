## 3471571 sentance pairs so far

Number one TODO: first pass on everything is done. Now make everything more resilient and accurate. 

| Source                                                                                                     | Notes                                                                                                            | Status                                          |
|----------------------------------------------------------------------------------------------------------|------------------------------------------------------------------------------------------------------------------|-------------------------------------------------|
| [d-addicts](http://www.d-addicts.com/forums/page/subtitles?sid=c00e06662e59c449c2b2814b22e7bc90#Japanese) | * ~600 dramas, ~5M sentance pairs,<br>  * fansubs,<br> * japanese & english subs in different parts of same page | * **crawled**<br/>* **parsed** <br/>* **matched**<br/>* 620408                                  |
| [OpenSubtitles](http://opus.lingfil.uu.se/OpenSubtitles2016.php)                                         | * 1.4M sentance pairs,<br> * professional translations, 1-1 en/jp matching (in same file)                        | * **crawled**<br/>* **parsed**<br/>* **matched**<br/>* 1381339  |
| [kitsunekko](http://kitsunekko.net/dirlist.php?dir=subtitles%2Fjapanese%2F)                              | * ~600 dramas/movies (largeley incomplete), ~3M pairs<br> * fansubs<br> * en/jp lists on different pages         | * **crawled**<br/>* **parsed**<br/>* **matched(?)** <br/> * 161792 |
| [subscene](http://v2.subscene.com/subtitles/a/japanese.aspx)                                             | * ~2000 movies/shows, ~5M raw sentance pairs, ~1.3M usable pairs<br> * mix of fansubs & professional translations                       | * **crawled**<br/>* **parsed**<br/>* **matched(?)** <br/> 810678 |
| [TED talks](https://www.ted.com/talks) | ~100k pairs | * **crawled**<br/> * **parsed**<br/>* **matched** </br>* 497294 |

### Numbers to beat

I'd like to make this the biggest open-source Japanese-English corpus out there. Looks like ~1M sentance pairs is the number to beat: http://www.phontron.com/japanese-translation-data.php?lang=en


### Roadblocks

* accessing paired translations
  * soln: crawl sub sites, pull down en and jp subs for matched films/tv shows
* Poor translations. I.e. I've seen subs that were generated by running another language's subs through google translate
  * soln: run language model over each movie/show's corpus. if average sentance quality is below some threshold, throw it out
* En/Jp subtitle mismatch. Sometimes the srt files don't have the same number of entries, and entries don't correspond to the same times.
  * soln: sentance alignment model. run encoder over en/jp srt files. pair up nearby sentances with similar thought vectors
* romanji transliterations
  * soln: throw out
* broken character encodings (gobblygook)
  * soln: convert to utf-8, throw out subs that can't be converted
* stuff that doesn't belong (i.e. "TRANSLATED BY ______")


### model publications

* https://wit3.fbk.eu/papers/WIT3-EAMT2012.pdf
* http://stp.lingfil.uu.se/~joerg/paper/opensubs2016.pdf
* http://www.ccl.kuleuven.be/~tallem/Paper_Belgisch_Staatsblad_Corpus.pdf






